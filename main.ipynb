{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273fc8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import backtrader as bt\n",
    "\n",
    "import CustomCSVData\n",
    "from Strategies import Momentum3, RollingVote\n",
    "from Report import generate_reports\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e281ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93ff45",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f413ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(ticker, start_date, end_date, interval, filename):\n",
    "    \"\"\"\n",
    "    Download data from Yahoo Finance\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        ticker (str): Ticker symbol\n",
    "        start_date (str): Start date in \"YYYY-MM-DD\" format\n",
    "        end_date (str): End date in \"YYYY-MM-DD\" format\n",
    "        interval (str): Data interval (e.g., '1d', '1h', '1m')\n",
    "        filename (str): Filename to save the data as CSV\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pd.DataFrame: DataFrame containing the downloaded data\n",
    "    \"\"\"\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt   = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    intraday_intervals = ['1m','2m','5m','15m','30m','60m','90m','1h']\n",
    "\n",
    "    if interval in intraday_intervals:\n",
    "        max_span = timedelta(days=60)\n",
    "        # enforce 60-day limit\n",
    "        if end_dt - start_dt > max_span:\n",
    "            print(\"Warning: Intraday data cannot exceed 60 days. Adjusting start_date.\")\n",
    "            start_dt = end_dt - max_span\n",
    "\n",
    "    df = yf.download(ticker, start=start_dt.strftime(\"%Y-%m-%d\"), end=end_dt.strftime(\"%Y-%m-%d\"), interval=interval, auto_adjust=True)  \n",
    "    if df is None or df.empty:\n",
    "        print(f\"No data found for {ticker} between {start_date} and {end_date}.\")\n",
    "        return False\n",
    "    \n",
    "    # Handle missing values by forward filling\n",
    "    df.ffill(inplace=True)\n",
    "\n",
    "    df.columns = df.columns.droplevel('Ticker')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns.name = None\n",
    "\n",
    "    # df.to_csv(filename)\n",
    "    # print(f\"Data for {ticker} saved to {filename}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8968060",
   "metadata": {},
   "source": [
    "## Data Splitting and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26bfc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, ema_length, rsi_length, macd_short, macd_long, bb_window):\n",
    "    \"\"\"\n",
    "    Create the following features:\n",
    "    - Exponential Moving Average (EMA)\n",
    "    - Relative Strength Index (RSI)\n",
    "    - Moving Average Convergence Divergence (MACD)\n",
    "    - Bollinger Bands (BB)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        df (pd.DataFrame): DataFrame containing stock data with 'Close' prices\n",
    "        ema_length (int): Length for EMA calculation\n",
    "        rsi_length (int): Length for RSI calculation\n",
    "        macd_short (int): Short length for MACD calculation\n",
    "        macd_long (int): Long length for MACD calculation\n",
    "        bb_window (int): Window length for Bollinger Bands calculation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        pd.DataFrame: DataFrame with added technical indicators and target variable\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df[f'EMA_{ema_length}'] = df['Close'].ewm(span=ema_length, adjust=False).mean()\n",
    "\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=rsi_length).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=rsi_length).mean()\n",
    "    rs = gain / loss\n",
    "    df[f'RSI_{rsi_length}'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    ema_short = df['Close'].ewm(span=macd_short, adjust=False).mean()\n",
    "    ema_long = df['Close'].ewm(span=macd_long, adjust=False).mean()\n",
    "    df['MACD'] = ema_short - ema_long\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    sma = df['Close'].rolling(window=bb_window).mean()\n",
    "    std = df['Close'].rolling(window=bb_window).std()\n",
    "    df['BB_Upper'] = sma + (std * 2)\n",
    "    df['BB_Lower'] = sma - (std * 2)\n",
    "\n",
    "    df['price_rise'] = np.where(df['Close'] > df['Close'].shift(1), 1, 0)\n",
    "    df['Target'] = df['price_rise'].shift(-1)\n",
    "\n",
    "\n",
    "    df.drop(columns=['price_rise'], inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efae0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_transform(df):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into training and testing sets (**80%** train, **20%** test). Standardize the raw features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        df (pd.DataFrame): DataFrame containing the features and target variable\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        pd.DataFrame: Training set\n",
    "        pd.DataFrame: Testing set\n",
    "        StandardScaler: Fitted scaler object\n",
    "    \"\"\"\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    cols = [col for col in train_df.columns if col not in ['Date']]\n",
    "    train_df[cols] = scaler.fit_transform(train_df[cols])\n",
    "    test_df[cols] = scaler.transform(test_df[cols])\n",
    "\n",
    "    return train_df, test_df, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c34de9",
   "metadata": {},
   "source": [
    "## Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e0828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(raw_df):\n",
    "    # FE Grid Search Setup\n",
    "    ema_lengths = [20]\n",
    "    rsi_lengths = [14]\n",
    "    macd_shorts = [12]\n",
    "    macd_longs = [26]\n",
    "    bb_windows = [20]\n",
    "    \n",
    "    # Model Hyperparameters\n",
    "    model_params = {\n",
    "        'SVM': {'C': [2,5,7,10,20]},\n",
    "        'RandomForest': {'n_estimators': [50, 100, 150, 200], 'max_depth': [5, 10, 20, 30]},\n",
    "        'LASSO': {'C': [0.01, 0.1, 1.0, 10.0]},\n",
    "        'KNN': {'n_neighbors': [3, 5, 7, 9, 11, 13]},\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    fe_combinations = list(itertools.product(ema_lengths, rsi_lengths, macd_shorts, macd_longs, bb_windows))\n",
    "    \n",
    "    total_fe_sets = len(fe_combinations)\n",
    "    total_runs = total_fe_sets * 32\n",
    "    \n",
    "    \n",
    "    global_run_count = 0\n",
    "\n",
    "    for count, fe_set in enumerate(fe_combinations, 1):\n",
    "        ema_len, rsi_len, macd_short, macd_long, bb_window = fe_set\n",
    "        \n",
    "        print(f\"\\nEvaluating Feature Set {count:3d} of {total_fe_sets}. Params: EMA={ema_len}, RSI={rsi_len}, MACD=({macd_short}, {macd_long}), BB={bb_window}\")\n",
    "        \n",
    "        processed_df = feature_engineering(\n",
    "            raw_df, \n",
    "            ema_length=ema_len, \n",
    "            rsi_length=rsi_len, \n",
    "            macd_short=macd_short, \n",
    "            macd_long=macd_long, \n",
    "            bb_window=bb_window, \n",
    "        )\n",
    "        \n",
    "        train_df, val_df = train_test_split(processed_df, test_size=0.25, shuffle=False)\n",
    "        \n",
    "        X_train = train_df.drop(columns=['Target','Date'])\n",
    "        y_train = train_df['Target']\n",
    "        X_val = val_df.drop(columns=['Target','Date'])\n",
    "        y_val = val_df['Target']\n",
    "        \n",
    "        fe_params = {\n",
    "            'ema_length': ema_len, 'rsi_length': rsi_len, \n",
    "            'macd_short': macd_short, 'macd_long': macd_long, 'bb_window': bb_window,\n",
    "        }\n",
    "\n",
    "\n",
    "        for model_name, param_grid in model_params.items():\n",
    "            # SVM\n",
    "            if model_name == 'SVM':\n",
    "                for C_val in param_grid['C']:\n",
    "                    global_run_count += 1\n",
    "                    model = SVC(C=C_val, kernel='linear', probability=False, max_iter=-1, random_state=SEED)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    predictions = model.predict(X_val)\n",
    "                    score = accuracy_score(y_val, predictions)\n",
    "                    \n",
    "                    print(f\"| Run {global_run_count:4d}/{total_runs} | {model_name} (C={C_val:.2f}) -> Accuracy: {score:.4f}\")\n",
    "\n",
    "                    current_run_results = {\n",
    "                        'model': model_name,\n",
    "                        'model_params': {'C': C_val},\n",
    "                        'fe_params': fe_params,\n",
    "                        'accuracy': score,\n",
    "                        'precision': precision_score(y_val, predictions, zero_division=0),\n",
    "                        'recall': recall_score(y_val, predictions, zero_division=0),\n",
    "                        'f1': f1_score(y_val, predictions, zero_division=0),\n",
    "                        'num_features': X_train.shape[1]\n",
    "                    }\n",
    "                    results.append(current_run_results)\n",
    "            \n",
    "            # LASSO\n",
    "            elif model_name == 'LASSO':\n",
    "                for C_val in param_grid['C']:\n",
    "                    global_run_count += 1\n",
    "                    model = LogisticRegression(penalty='l1', C=C_val, solver='liblinear', random_state=SEED)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    predictions = model.predict(X_val)\n",
    "                    score = accuracy_score(y_val, predictions)\n",
    "                    \n",
    "                    print(f\"| Run {global_run_count:4d}/{total_runs} | {model_name} (C={C_val:.4f}) -> Accuracy: {score:.4f}\")\n",
    "\n",
    "                    current_run_results = {\n",
    "                        'model': model_name,\n",
    "                        'model_params': {'C': C_val},\n",
    "                        'fe_params': fe_params,\n",
    "                        'accuracy': score,\n",
    "                        'precision': precision_score(y_val, predictions, zero_division=0),\n",
    "                        'recall': recall_score(y_val, predictions, zero_division=0),\n",
    "                        'f1': f1_score(y_val, predictions, zero_division=0),\n",
    "                        'num_features': X_train.shape[1]\n",
    "                    }\n",
    "                    results.append(current_run_results)\n",
    "\n",
    "            # KNN\n",
    "            elif model_name == 'KNN':\n",
    "                for n_neighbors in param_grid['n_neighbors']:\n",
    "                    global_run_count += 1\n",
    "                    model = KNeighborsClassifier(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    predictions = model.predict(X_val)\n",
    "                    score = accuracy_score(y_val, predictions)\n",
    "                    \n",
    "                    print(f\"| Run {global_run_count:4d}/{total_runs} | {model_name} (Neighbors={n_neighbors}) -> Accuracy: {score:.4f}\")\n",
    "\n",
    "                    current_run_results = {\n",
    "                        'model': model_name,\n",
    "                        'model_params': {'n_neighbors': n_neighbors},\n",
    "                        'fe_params': fe_params,\n",
    "                        'accuracy': score,\n",
    "                        'precision': precision_score(y_val, predictions, zero_division=0),\n",
    "                        'recall': recall_score(y_val, predictions, zero_division=0),\n",
    "                        'f1': f1_score(y_val, predictions, zero_division=0),\n",
    "                        'num_features': X_train.shape[1]\n",
    "                    }\n",
    "                    results.append(current_run_results)\n",
    "            \n",
    "            # Random Forest\n",
    "            elif model_name == 'RandomForest':\n",
    "                for n_est in param_grid['n_estimators']:\n",
    "                    for max_d in param_grid['max_depth']:\n",
    "                        global_run_count += 1\n",
    "                        model = RandomForestClassifier(n_estimators=n_est, max_depth=max_d, random_state=SEED, n_jobs=-1)\n",
    "                        model.fit(X_train, y_train)\n",
    "                        predictions = model.predict(X_val)\n",
    "                        score = accuracy_score(y_val, predictions)\n",
    "                        \n",
    "                        print(f\"| Run {global_run_count:4d}/{total_runs} | {model_name} (Est={n_est}, Depth={max_d}) -> Accuracy: {score:.4f}\")\n",
    "\n",
    "                        current_run_results = {\n",
    "                            'model': model_name,\n",
    "                            'model_params': {'n_estimators': n_est, 'max_depth': max_d},\n",
    "                            'fe_params': fe_params,\n",
    "                            'accuracy': score,\n",
    "                            'precision': precision_score(y_val, predictions, zero_division=0),\n",
    "                            'recall': recall_score(y_val, predictions, zero_division=0),\n",
    "                            'f1': f1_score(y_val, predictions, zero_division=0),\n",
    "                            'num_features': X_train.shape[1]\n",
    "                        }\n",
    "                        results.append(current_run_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd13934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params_per_model(results, evaluation_metric='f1'):\n",
    "    best_by_model = {}\n",
    "    \n",
    "    model_best_scores = {\n",
    "        'SVM': -1.0,\n",
    "        'RandomForest': -1.0,\n",
    "        'LASSO': -1.0,\n",
    "        'KNN': -1.0,\n",
    "    }\n",
    "    \n",
    "    for run in results:\n",
    "        model_name = run['model']\n",
    "        accuracy = run[evaluation_metric]\n",
    "        \n",
    "        if accuracy > model_best_scores[model_name]:\n",
    "            model_best_scores[model_name] = accuracy\n",
    "            best_by_model[model_name] = run\n",
    "    \n",
    "    sorted_models = sorted(model_best_scores.items(), key=lambda x: x[1])\n",
    "\n",
    "    worst_two = [sorted_models[0][0], sorted_models[1][0]]\n",
    "\n",
    "    for m in worst_two:\n",
    "        if m in best_by_model:\n",
    "            del best_by_model[m]\n",
    "\n",
    "    return best_by_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90f1eb",
   "metadata": {},
   "source": [
    "## Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12f3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions(ticker, best_results, train_df, test_df, scaler):\n",
    "    \n",
    "    for model_name, best_run in best_results.items():\n",
    "        fe_params = best_run['fe_params']\n",
    "        \n",
    "        fe_train_df = feature_engineering(\n",
    "            train_df, \n",
    "            ema_length=fe_params['ema_length'], \n",
    "            rsi_length=fe_params['rsi_length'], \n",
    "            macd_short=fe_params['macd_short'], \n",
    "            macd_long=fe_params['macd_long'], \n",
    "            bb_window=fe_params['bb_window'],\n",
    "        )\n",
    "\n",
    "        fe_test_df = feature_engineering(\n",
    "            test_df, \n",
    "            ema_length=fe_params['ema_length'], \n",
    "            rsi_length=fe_params['rsi_length'], \n",
    "            macd_short=fe_params['macd_short'], \n",
    "            macd_long=fe_params['macd_long'], \n",
    "            bb_window=fe_params['bb_window'],\n",
    "        )\n",
    "        \n",
    "        X_train = fe_train_df.drop(columns=['Target','Date'])\n",
    "        y_train = fe_train_df['Target']\n",
    "        X_test = fe_test_df.drop(columns=['Target','Date'])\n",
    "        y_test = fe_test_df['Target']\n",
    "        \n",
    "        model_params = best_run['model_params']\n",
    "        \n",
    "        if model_name == 'SVM':\n",
    "            model = SVC(C=model_params['C'], kernel='linear', probability=False, random_state=SEED)\n",
    "        elif model_name == 'RandomForest':\n",
    "            model = RandomForestClassifier(n_estimators=model_params['n_estimators'], max_depth=model_params['max_depth'], random_state=SEED, n_jobs=-1)\n",
    "        elif model_name == 'LASSO':\n",
    "            model = LogisticRegression(penalty='l1', C=model_params['C'], solver='liblinear', random_state=SEED)\n",
    "        elif model_name == 'KNN':\n",
    "            model = KNeighborsClassifier(n_neighbors=model_params['n_neighbors'], n_jobs=-1)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        print(f\"Test Accuracy for Best {model_name}: {accuracy:.4f}\")\n",
    "        print(f\"Test Precision for Best {model_name}: {precision:.4f}\\n\")\n",
    "\n",
    "        result_df = pd.DataFrame({\n",
    "            'Date': fe_test_df['Date'],\n",
    "            'Open': fe_test_df['Open'],\n",
    "            'High': fe_test_df['High'],\n",
    "            'Low': fe_test_df['Low'],\n",
    "            'Close': fe_test_df['Close'],\n",
    "            'Volume': fe_test_df['Volume'],\n",
    "            'Actual': y_test,\n",
    "            'Predicted': predictions\n",
    "        })\n",
    "\n",
    "        result_df[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.inverse_transform(result_df[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "\n",
    "        result_df.to_csv(f'./data/predictions/{ticker}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20110f6e",
   "metadata": {},
   "source": [
    "## Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e07b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(ticker, data_filename, strategy_class):\n",
    "    cerebro = bt.Cerebro()\n",
    "    cerebro.broker.set_cash(100000.0)\n",
    "    cerebro.broker.setcommission(commission=0.001)\n",
    "    cerebro.addsizer(bt.sizers.PercentSizer, percents=50)\n",
    "\n",
    "    data = CustomCSVData.CustomCSVData(\n",
    "        dataname=data_filename,\n",
    "        preset='predicted',\n",
    "    )\n",
    "\n",
    "    cerebro.adddata(data)\n",
    "\n",
    "    cerebro.addstrategy(strategy_class)\n",
    "    cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\n",
    "\n",
    "    print(f\"Starting Portfolio Value: {cerebro.broker.getvalue():.2f}\")\n",
    "    results = cerebro.run()\n",
    "    print(f\"Final Portfolio Value: {cerebro.broker.getvalue():.2f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526113c",
   "metadata": {},
   "source": [
    "## Single Stock Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79dfdc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_stock_backtest(ticker):\n",
    "    df = download_data(ticker, '2000-01-01', '2021-11-12', '1d', f'{ticker}_data.csv')\n",
    "    train_df, test_df, scaler = split_transform(df)\n",
    "\n",
    "    tunned_results = tune_model(train_df)\n",
    "\n",
    "    best_results = find_best_params_per_model(tunned_results, evaluation_metric='f1')\n",
    "\n",
    "    test_predictions(ticker, best_results, train_df, test_df,scaler)\n",
    "\n",
    "    for model in best_results.keys():\n",
    "        generate_reports(backtest(ticker, f'./data/predictions/{ticker}_{model}.csv', Momentum3), ticker_name=ticker, model_name=model, strategy_name=\"Momentum3\")\n",
    "        generate_reports(backtest(ticker, f'./data/predictions/{ticker}_{model}.csv', RollingVote), ticker_name=ticker, model_name=model, strategy_name=\"RollingVote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71331cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_stock_backtest(\"TSCO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae8dee",
   "metadata": {},
   "source": [
    "## 10 Stock Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fc637ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_df = pd.read_csv('./data/tickers_nyse.csv')\n",
    "nasd_df = pd.read_csv('./data/tickers_nasd.csv')\n",
    "\n",
    "tickers_df = pd.concat([nyse_df, nasd_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0edc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_df['IPOyear'] = pd.to_numeric(tickers_df['IPOyear'], errors='coerce')\n",
    "tickers_df = tickers_df[(tickers_df['IPOyear'].notna()) & (tickers_df['IPOyear'] <= 2000)]\n",
    "filtered_tickers = tickers_df['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be121475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Tickers for Backtesting: ['ULTI', 'AUDC', 'CTIB', 'LMNX', 'RGEN', 'CIEN', 'TSCO', 'WTS', 'VRSN', 'KOPN']\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(filtered_tickers)\n",
    "\n",
    "valid = []\n",
    "tried = set()\n",
    "\n",
    "for ticker in filtered_tickers:\n",
    "    if len(valid) == 10:\n",
    "        break\n",
    "\n",
    "    if ticker in tried:\n",
    "        continue\n",
    "    tried.add(ticker)\n",
    "\n",
    "    try:\n",
    "        single_stock_backtest(ticker)\n",
    "        valid.append(ticker)\n",
    "        print(f\"Valid: {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid: {ticker} ({e})\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
